{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Iris Dataset Analysis\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a step by step analysis of the renowned Iris dataset, offering a comprehensive guide for analyzing its various dimensions with Python. In addition, the content provided in this notebook aims to clearly explain each of the scripts created in Python for this analysis as well as the modules and functions used.     \n",
    "It takes users through a structured journey, starting with dataset loading and basic exploration, progressing to understanding variable types and modeling techniques. Subsequent sections delve into categorical data analysis and exploration of numerical variables via summary statistics and histograms. Then, further sections explore with scatterplots and heat map the relationship between the variables and ends with a program that prints the results of a correlation analysis carried out between each two variables of the dataset.       \n",
    "This systematic approach empowers users to grasp the dataset's intricacies and relationships, thereby aiding informed analysis and decision-making in relevant research or applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Loading the Iris dataset:\n",
    "\n",
    "The program load_iris.py has been created to facilitate the loading of the Iris dataset into the programs summary.py, histogram.py, scatterplot.py, heatmap.py, and correlation.py. The function load_dataset is defined in load_iris.py and used in each of the mentioned programs to call in and run the script below in order to load the Iris dataset there.    \n",
    "\n",
    "The script below can be broken down as follow:\n",
    "- Importing modules:\n",
    "    - The module OS is used to check if a file exists.\n",
    "    - The module pandas is used to handle the Iris dataset in DataFrame format.\n",
    "- Fuctions definitions:\n",
    "    - load_dataset(file_name) takes a filename as input and returns a DataFrame containing the Iris dataset. Within this function other functions are used:\n",
    "        - It first checks if the specified file exists using os.path.exists(file_name). If the file does not exist, it prints a message indicating the absence of the file and exits the program with quit(1).\n",
    "        - If the file exists, it loads the dataset into a DataFrame using pd.read_csv(file_name, header=None), assuming the dataset is in CSV format without a header row.\n",
    "        - Then, it defines column titles for the DataFrame using a predefined list column_title.\n",
    "        - Finally, it sets the column titles as headers for the DataFrame and returns the resulting DataFrame.\n",
    "- Main Execution:\n",
    "    - if \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\": This condition checks if the script is being run directly (not imported as a module).\n",
    "    - load_dataset('iris.data'): Calls the load_dataset function with the filename 'iris.data'. If the script is executed directly, this line will execute the function and load the Iris dataset. If the file does not exist, it will print a warning message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'os' to check if the file exists\n",
    "import os\n",
    "# Import 'pandas' for the data summary\n",
    "import pandas as pd\n",
    "\n",
    "def load_dataset(file_name):\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_name):\n",
    "        # if file does not exist, then output a message\n",
    "        print(f'{file_name} does not exist. The \"iris.data\" file needs to be saved in the repository pands-project')\n",
    "        quit(1)\n",
    "    \n",
    "    # Load dataset \n",
    "    df = pd.read_csv(file_name, header=None)\n",
    "\n",
    "    # Adding Column titles to the iris.data\n",
    "    # Defining the column titles\n",
    "    column_title = [\"Sepal Length (cm)\", \"Sepal Width (cm)\", \"Petal Length (cm)\", \"Petal Width (cm)\", \"Species\"]\n",
    "\n",
    "    # Setting column titles as headers to the dataframe\n",
    "    df.columns = column_title\n",
    "\n",
    "    # Load dataset and return it\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_dataset ('iris.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the Iris dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan for 'README file'\n",
    "\n",
    "GitHub documentation on README file was consulted and from it the suggested headings were implemented into the README file so as to ensure that all the requirements are attended. The main part of the README file is the section About This Project which presents the Author's understanding and appropriate research about the IRIS dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan Task 'Summary': \n",
    "\n",
    "Review the videos from Topic 07 - Files, Topic 09 - Errors and Topic 10 - Pandas.\n",
    "\n",
    "\n",
    "This needs to be updated after reviewing of the videos and searching for new material:\n",
    "Input:\n",
    "- Use the function open(XX, 'wt') from Pandas to create the text files for each variable with their name on the top - refer to lab07.07-loadStudents.py.\n",
    "- Deal with errors (dropna, different file extension type, etc) - reference es.py file. Might be able to do this using pandas only.\n",
    "- Load the dataset - module pandas, function read_csv()\n",
    "- Identify the type of variables in the dataset - function dtypes ('is this a function?').\n",
    "- Check missing values for each variable - function isnull().sum() - see penguins.ipynb.\n",
    "    \n",
    "\n",
    "Output: \n",
    "- A text file should be created for each variable type.\n",
    "- Error messages ...\n",
    "- It should count the number of NaN for each variable and if any NaN is found then a message is displayed with the number of null data and a proper rationale.\n",
    "- It should show a random \n",
    "- If the variable is categorical then it should show the different value types and their counts.\n",
    "- If the variable is continuous then it should display the descriptive summary of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Files: https://www.dataquest.io/blog/read-file-python/\n",
    "Check if file exists with OS: https://docs.python.org/3/library/os.path.html\n",
    "To understand what is the extension .data (iris.data) and how to work with it: https://www.askpython.com/python/examples/read-data-files-in-python#\n",
    "To add the title to the dataframe using pandas = https://sparkbyexamples.com/pandas/pandas-add-column-names-to-dataframe/\n",
    "Added header=None: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- By looking into the iris.data, it was noticed that the columns do not have a heading. By reading the file iris.names that was download zipped together with the downloaded iris.data file it was possible to identify that the columns are: sepal length in cm, sepal width in cm, petal length in cm, petal width in cm, class. \n",
    "- Before adding the columns titles to the dataframe there was no header so header=None had to be added as per pandas documentation. This is because the header was added to existing DataFrame and not while reading a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "\n",
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
